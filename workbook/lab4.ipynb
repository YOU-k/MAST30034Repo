{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 4 Overview\n",
    "#### First Half\n",
    "- Doing basic statistical models with Python\n",
    "- R to Python equivalents \n",
    "\n",
    "#### Second Half\n",
    "- *Questions?*\n",
    "- *Industry techniques and basic procedures?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Learning in Python\n",
    "- Regression\n",
    "- General Linear Models (GLM, more from MAST30027...)\n",
    "- LASSO and Ridge Regression \n",
    "- Non-regression based methods\n",
    "\n",
    "We will be using `\"100k_yellow_2015_05.csv\"` which can be obtained from Canvas.  \n",
    "This dataset is a 100k sample from (https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-05.csv) \n",
    "\n",
    "\n",
    "```python\n",
    "import urllib\n",
    "\n",
    "outputDir = \"../Data/Lab4/100k_yellow_2015_05.csv\"\n",
    "url = \"https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2015-05.csv\"\n",
    "urllib.request.urlretrieve(url, outputDir)\n",
    "print(f\"Done downloading {fname} to ./{outputDir}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the equivalent package lm or glm\n",
    "from statsmodels.formula.api import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# read in the data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../Data/Lab4/100k_yellow_2015_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                   int64\n",
       "tpep_pickup_datetime      object\n",
       "tpep_dropoff_datetime     object\n",
       "passenger_count            int64\n",
       "trip_distance            float64\n",
       "pickup_longitude         float64\n",
       "pickup_latitude          float64\n",
       "RateCodeID                 int64\n",
       "store_and_fwd_flag        object\n",
       "dropoff_longitude        float64\n",
       "dropoff_latitude         float64\n",
       "payment_type               int64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(From the lab): As an example, let's try to predict `total_amount` using `fare_amount, tip_amount, toll_amount, trip_distance, VendorID` as predictors.\n",
    "\n",
    "Some things to take note:\n",
    "- `tip_amount` is only valid for `payment_type == 1` (card)\n",
    "- `VendorID` is categorical, with only two possible values (`1` or `2`) so we should make it boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61887</th>\n",
       "      <td>12.25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61888</th>\n",
       "      <td>8.16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61889</th>\n",
       "      <td>7.55</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61890</th>\n",
       "      <td>11.80</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61891</th>\n",
       "      <td>11.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_amount  fare_amount  tip_amount  tolls_amount  trip_distance  \\\n",
       "61887         12.25          8.0        2.45           0.0           1.70   \n",
       "61888          8.16          5.0        1.36           0.0           0.89   \n",
       "61889          7.55          4.5        1.25           0.0           0.50   \n",
       "61890         11.80          9.0        2.00           0.0           1.80   \n",
       "61891         11.00          8.0        2.20           0.0           1.90   \n",
       "\n",
       "       VendorID  \n",
       "61887     False  \n",
       "61888     False  \n",
       "61889      True  \n",
       "61890      True  \n",
       "61891      True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter dataframe\n",
    "COL_FILTER = ['total_amount', 'fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "df_filtered = df.loc[df['payment_type'] == 1, COL_FILTER].reset_index(drop=True)\n",
    "df_filtered['VendorID'] = df_filtered['VendorID'] == 1\n",
    "\n",
    "df_filtered.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(From the lab): We are looking for linear relationships between our chosen response `total_amount`.   \n",
    "(Me): Now I'm not sure what kind of life you've lived, but I'm fairly certain that we can infer that `total_amount` will have a positive linear relationship with `fare_amount`. Let's see a quick plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filtered[['total_amount', 'fare_amount']].plot.scatter(x='fare_amount', y='total_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, obviously this looks like an overall positive linear relationship.\n",
    "- How might we statistically test this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R, we would do something like this for (Ordinary) Least Squares:\n",
    "```R\n",
    ">>> fit <- lm(total_amount~fare_amount + tip_amount + tolls_amount + trip_distance + VendorID ,data=dat_fit)\n",
    ">>> summary(fit)\n",
    "```\n",
    "```\n",
    "Call:\n",
    "lm(formula = total_amount ~ fare_amount + tip_amount + tolls_amount +\n",
    "trip_distance + VendorID, data = dat_fit)\n",
    "\n",
    "Residuals:\n",
    "Min     1Q      Median  3Q     Max\n",
    "-1.4727 -0.3295 -0.1528 0.1747 1.7975\n",
    "\n",
    "Coefficients:\n",
    "               Estimate Std. Error t value Pr(>|t|)\n",
    "(Intercept)    1.162154   0.002986 389.194  <2e-16 ***\n",
    "fare_amount    0.993388   0.000315 3153.943 <2e-16 ***\n",
    "tip_amount     1.006511   0.000826 1218.553 <2e-16 ***\n",
    "tolls_amount   0.979325   0.001285 762.428  <2e-16 ***\n",
    "trip_distance  0.011742   0.000963 12.194   <2e-16 ***\n",
    "VendorIDTRUE  -0.003125   0.002914 -1.073    0.283\n",
    "---\n",
    "Signif. codes:\n",
    "0 ^a˘A¨Y***^a˘A´Z 0.001 ^a˘A¨Y**^a˘A´Z 0.01 ^a˘A¨Y*^a˘A´Z 0.05 ^a˘A¨Y.^a˘A´Z 0.1 ^a˘A¨Y ^a˘A´Z 1\n",
    "\n",
    "Residual standard error: 0.362 on 61886 degrees of freedom\n",
    "Multiple R-squared: 0.9994,          Adjusted R-squared: 0.9994\n",
    "F-statistic: 1.953e+07 on 5 and 61886 DF, p-value: < 2.2e-16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, whatever you can do in R can also done in Python (to an extent).  \n",
    "Documentation Source: https://www.statsmodels.org/dev/generated/statsmodels.formula.api.ols.html?highlight=ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = ols(formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount + trip_distance + VendorID\",\n",
    "         data=df_filtered).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 1.953e+07\n",
      "Date:                Sat, 29 Aug 2020   Prob (F-statistic):               0.00\n",
      "Time:                        20:49:57   Log-Likelihood:                -24933.\n",
      "No. Observations:               61892   AIC:                         4.988e+04\n",
      "Df Residuals:                   61886   BIC:                         4.993e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            1.1622      0.003    389.194      0.000       1.156       1.168\n",
      "VendorID[T.True]    -0.0031      0.003     -1.073      0.283      -0.009       0.003\n",
      "fare_amount          0.9934      0.000   3153.943      0.000       0.993       0.994\n",
      "tip_amount           1.0065      0.001   1218.553      0.000       1.005       1.008\n",
      "tolls_amount         0.9793      0.001    762.428      0.000       0.977       0.982\n",
      "trip_distance        0.0117      0.001     12.194      0.000       0.010       0.014\n",
      "==============================================================================\n",
      "Omnibus:                     7709.498   Durbin-Watson:                   0.295\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5927.474\n",
      "Skew:                           0.662   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.261   Cond. No.                         46.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The table structure is a bit different, though it is identical in value with R's output.  \n",
    "- The coefficient table is the same, but now includes a 95% CI for the beta coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Is this model good?\n",
    "    - The $R^2$ value is 0.999 which is insanely large. As a rule of thumb, large $R^2$ values indicate a good fit. \n",
    "    - *Perhaps too good of a fit...*\n",
    "    - AIC itself isn't important, however, if we compare it to another model (let's say an alternative model with different features chosen)...\n",
    "    - If we have a hypothesis for a null model ($\\beta=0$) vs our fitted model ($\\beta\\neq0$), then we can look at the `F-statistc = 1.953e+07`. The corresponding p-value of  this F statistic is `0.00`, which is less than $\\alpha=0.05$, so we can conclude that our fitted model is better than a null model. In other words, we reject the null hypothesis and conclude that we believe the intercept parameters to be non-zero.\n",
    "    \n",
    "    \n",
    "- How might we improve this model?\n",
    "    - If we look at the parameters, we may wish to exclude `VendorID[T.True]` as it is not significant with p-value `0.283 > 0.05`. Perhaps we should drop this attribute and fit another model without it.\n",
    "    - Additionally, we can do some feature engineering (run a decision tree and look at the splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 2.441e+07\n",
      "Date:                Sat, 29 Aug 2020   Prob (F-statistic):               0.00\n",
      "Time:                        20:50:23   Log-Likelihood:                -24933.\n",
      "No. Observations:               61892   AIC:                         4.988e+04\n",
      "Df Residuals:                   61887   BIC:                         4.992e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         1.1606      0.003    440.908      0.000       1.155       1.166\n",
      "fare_amount       0.9934      0.000   3153.978      0.000       0.993       0.994\n",
      "tip_amount        1.0065      0.001   1218.552      0.000       1.005       1.008\n",
      "tolls_amount      0.9793      0.001    762.428      0.000       0.977       0.982\n",
      "trip_distance     0.0118      0.001     12.209      0.000       0.010       0.014\n",
      "==============================================================================\n",
      "Omnibus:                     7704.062   Durbin-Watson:                   0.295\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5928.267\n",
      "Skew:                           0.662   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.262   Cond. No.                         34.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "fitter = ols(formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount + trip_distance\",\n",
    "         data=df_filtered).fit()\n",
    "print(fitter.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have to values of AIC to compare with, which one is better...?\n",
    "    - Well, we see a small decrease in AIC and a large decrease in BIC. Hence, we can say that the model without `VendorID` is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([49877.70777173292, 49876.858381244325],\n",
       " [49931.90664899058, 49922.024112292376])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fit.aic, fitter.aic], [fit.bic, fitter.bic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO \n",
    "- One of many ways to avoid overfitting \n",
    "- Bit of a work around to install with Python in general.\n",
    "- Refer to the next section for an installation guide on Windows / Installing fortran compiler for Linux\n",
    "- **or you can use R for this**\n",
    "\n",
    "Quick overview:\n",
    "- LASSO may cause coefficients to be set to 0\n",
    "- To prevent this, we need to standardize the predictor X matrixs (aka your sample points) to have $\\mu=0, \\sigma^2=1$\n",
    "\n",
    "Pros:\n",
    "- Computationally cheaper than stepwise and (obviously) best subset\n",
    "- Works well for high dimensions\n",
    "\n",
    "Cons:\n",
    "- Results are sensitive to choice of parameters (notably $\\lambda$)\n",
    "- Doesn't work as well when all the features are significant or coefficient values are large\n",
    "- Biased estimator (only OLS is unbiased)\n",
    "\n",
    "Revise in your own time if you've forgotten:\n",
    "- Lecture 4 (variable selection)\n",
    "- LSM topic 5 (`ch05_handout`) slide 141/141\n",
    "![lasso](./cloud/lasso.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yCOLS = ['total_amount']\n",
    "xCOLS = ['fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "\n",
    "# standardize (by calculating the zscore) so our data has mean 0 and var 1\n",
    "from scipy.stats import zscore\n",
    "df_standard = df_filtered[xCOLS].astype(float).apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fare_amount  tip_amount  tolls_amount  trip_distance  VendorID\n",
       "mean       0.0000      0.0000       -0.0000        -0.0000   -0.0000\n",
       "std        1.0000      1.0000        1.0000         1.0000    1.0000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format output to 2 decimal places\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "df_standard.describe().loc[['mean','std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `df_standard` has  $\\mu=0, \\sigma=1(=\\sigma^2)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the code below for `glmnet` will most likely cause issues (yep, **another** workaround to do). R is natively built for this, but I have been more accustomed to using `glmnet` with Python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can fit our model\n",
    "from glmnet import ElasticNet\n",
    "\n",
    "lasso_fit = ElasticNet()\n",
    "lasso_fit.fit(df_standard.values, df_filtered[yCOLS].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to look at the shrinking parameter $\\lambda$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda value for LASSO: 0.23665078615126328\n"
     ]
    }
   ],
   "source": [
    "# this can be accessed using the .lambda_best_ method after fitting!\n",
    "print(f'Best lambda value for LASSO: {lasso_fit.lambda_best_[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about our coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>18.0736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>11.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>2.5958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>1.3317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficient\n",
       "Intercept          18.0736\n",
       "fare_amount        11.2272\n",
       "tip_amount          2.5958\n",
       "tolls_amount        1.3317\n",
       "trip_distance       0.0000\n",
       "VendorID            0.0000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can access the attributes to get your coefficients\n",
    "# refer to https://github.com/civisanalytics/python-glmnet/blob/master/glmnet/linear.py for full details\n",
    "pd.DataFrame(index = ['Intercept'] + xCOLS, \n",
    "             data= [lasso_fit.intercept_] + list(lasso_fit.coef_), \n",
    "             columns = ['Coefficient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `trip_distance` and `VendorID` have *shrunk* to 0. You can use `lasso_fit.predict(x)` to the predict a new set of observations by passing through the `x` matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a GLM\n",
    "- Well, this is exactly what you *should* be learning in MAS (MAST30027) right now\n",
    "\n",
    "(From the lab): The `passenger_count` attribute is discrete and non-negative. If we were to predict it, a linear model will not be sufficient. \n",
    "- (From the lab): We know that a poisson distribution takes in non-negative integer values, so we can use the Poisson family of GLMs to model this. \n",
    "- (From the lab): We will use `total_amount, trip_distance, VendorID` as our regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:        passenger_count   No. Observations:                99999\n",
      "Model:                            GLM   Df Residuals:                    99995\n",
      "Model Family:                 Poisson   Df Model:                            3\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -1.4936e+05\n",
      "Date:                Tue, 25 Aug 2020   Deviance:                       69274.\n",
      "Time:                        11:49:27   Pearson chi2:                 8.50e+04\n",
      "No. Iterations:                     5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            0.7194      0.004    161.801      0.000       0.711       0.728\n",
      "VendorID[T.True]    -0.4742      0.005    -93.639      0.000      -0.484      -0.464\n",
      "total_amount        -0.0006      0.000     -1.536      0.124      -0.001       0.000\n",
      "trip_distance        0.0035      0.001      2.584      0.010       0.001       0.006\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import families\n",
    "\n",
    "# convert VendorID to categorical\n",
    "df['VendorID'] = df['VendorID'] == 1\n",
    "\n",
    "fit = glm(formula=\"passenger_count ~ total_amount + trip_distance + VendorID\",\n",
    "         data=df, family=families.Poisson()).fit()\n",
    "\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that `total_amount` is insignificant (`p-val=0.124>0.05`)\n",
    "- Conclude that the total fare amount does not really affect the number of passengers in a trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "- Is using regression on X attribute / specific dataset even a good choice...?\n",
    "    - The answer is yes, it is a good choice *to try*\n",
    "    - BUT also try other methods...\n",
    "    \n",
    "    \n",
    "- What are the pros and cons of stepwise regression?\n",
    "    - Forward Selection (start from nothing and end until significant)\n",
    "    - Backward Elimination (start with everything and end until no more can be removed)\n",
    "    - Not always the best results...\n",
    "    \n",
    "    \n",
    "- What is best subset regression and the pros and cons of it?\n",
    "    - A brute-force like method of fitting *all posssible regressuibs* or *all possible models*\n",
    "    - Unlike stepwise, this method fits all possible models based on the variables specified, so you will get the best model possible\n",
    "    ![test](https://i.kym-cdn.com/photos/images/newsfeed/001/718/138/147.jpg)\n",
    "    \n",
    "    \n",
    "    \n",
    "- What is an assumption we make when we fit linear regression models?\n",
    "    - Well, the data has to be linearly seperable. \n",
    "    - Does this also apply to other models too...? (Recall SVM and kernel function which we can use)\n",
    "    - Perhaps another model might suit the dataset... (Trees, Neural Networks, Clustering, etc...)\n",
    "    \n",
    "    \n",
    "- If you were to use a decision tree, how would you compare between two different fits? \n",
    "    - Look at Gini Impurity (probability of an incorrectly classified instance)\n",
    "    \n",
    "\n",
    "- How about baselines or other predictive machine learning models?\n",
    "    - Precision, Recall, Classification Accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering?\n",
    "- We want to see if the the profitability of zones remains consistent with respect to hour of day, day of week and pickup location. The distribution of profitable zones should be similar across all years.\n",
    "- How is a zone profitable? Frequency of trips? Duration of trips? Best \"earners\"? etc...\n",
    "- You could create such a feature and scale it accordingly...\n",
    "- Perhaps the expected dollar per minute + possible tolls scaled by the expected frequency of trips...\n",
    "\n",
    "- Just remember that trip frequency $\\approx$ taxi demand in a zone (you don't know the number of taxis in a zone at the time)\n",
    "- Variable rate fares: *\"50 cents per 1/5 mile when travelling above 12mph OR 50 cents per 60 seconds in slow traffic or when the vehicle is stopped.\"*\n",
    "- Profit rates might assume crude approximations degrading into linear distance / constant velocity / etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Guide for glmnet Windows\n",
    "- Documentation for Python `glmnet`: https://github.com/civisanalytics/python-glmnet\n",
    "\n",
    "#### Method 0 (Preffered):\n",
    "- Face reality and accept that Windows breaks a lot of things\n",
    "- After accepting reality, uninstall anaconda and any python environment you have installed\n",
    "- Complete all of with Method 1\n",
    "- Launch Jupyter with `jupyter notebook` and copy paste the link into your browser!\n",
    "\n",
    "#### Method 1:\n",
    "- Install WSL (refer to lab1's link)\n",
    "- Run these commands:\n",
    "    - `sudo apt-get install python3`\n",
    "    - `sudo apt-get install python3-pip`\n",
    "- Done. You now have `python3` on linux working!\n",
    "- Install packages:\n",
    "    - `pip3 install pandas matplotlib seaborn numpy notebook geopandas folium bokeh` (and so on...)\n",
    "- Install `glmnet`:\n",
    "    1. `sudo add-apt-repository ppa:jonathonf/gcc-7.1`\n",
    "    2. `sudo apt-get update`\n",
    "    3. `sudo apt-get install gcc-7 g++-7`\n",
    "    4. `sudo apt-get install gfortran-7`\n",
    "    5. `sudo apt-get install gfortran`\n",
    "    6. `pip3 install glmnet`\n",
    "- Now you can use Jupyter Notebooks' bash magic to run the required parts\n",
    "- =======================================================================\n",
    "- If error, try https://stackoverflow.com/questions/46516394/how-to-install-libgfortran-so-4-on-ubuntu-16-06\n",
    "- Else if the above step doesn't work, move onto Method 2\n",
    "\n",
    "#### Method 2:\n",
    "- idk you could try this link: https://stackoverflow.com/a/56444043\n",
    "\n",
    "#### Method 3 (Easiest):\n",
    "- Just use `R` if you *really* want to do LASSO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
